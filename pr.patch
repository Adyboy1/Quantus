diff --git a/quantus/helpers/model/pytorch_model.py b/quantus/helpers/model/pytorch_model.py
index cb004c6b..92e3f27b 100644
--- a/quantus/helpers/model/pytorch_model.py
+++ b/quantus/helpers/model/pytorch_model.py
@@ -108,25 +108,27 @@ def _get_model_with_linear_top(self) -> torch.nn:
 
     def _obtain_predictions(self, x, model_predict_kwargs):
         pred = None
-        if PreTrainedModel is not None and isinstance(self.model, PreTrainedModel):
+        if PreTrainedModel is not None:
             # BatchEncoding is the default output from Tokenizers which contains
             # necessary keys such as `input_ids` and `attention_mask`.
             # It is also possible to pass a Dict with those keys.
-            if not (
-                isinstance(x, BatchEncoding)
-                or (
-                    isinstance(x, dict) and ("input_ids" in x and "attention_mask" in x)
-                )
-            ):
-                raise ValueError(
-                    "When using HuggingFace pretrained models, please use Tokenizers output for `x` "
-                    "or make sure you're passing a dict with input_ids and attention_mask as keys"
-                )
-            pred = self.model(**x, **model_predict_kwargs).logits
-            if self.softmax:
-                return torch.softmax(pred, dim=-1)
-            return pred
-        elif isinstance(self.model, nn.Module):
+            if isinstance(self.model, PreTrainedModel):
+                if not (
+                    isinstance(x, BatchEncoding)
+                    or (
+                        isinstance(x, dict)
+                        and ("input_ids" in x and "attention_mask" in x)
+                    )
+                ):
+                    raise ValueError(
+                        "When using HuggingFace pretrained models, please use Tokenizers output for `x` "
+                        "or make sure you're passing a dict with input_ids and attention_mask as keys"
+                    )
+                pred = self.model(**x, **model_predict_kwargs).logits
+                if self.softmax:
+                    return torch.softmax(pred, dim=-1)
+                return pred
+        if isinstance(self.model, nn.Module):
             pred_model = self.get_softmax_arg_model()
             return pred_model(torch.Tensor(x).to(self.device), **model_predict_kwargs)
         raise ValueError("Predictions cant be null")
diff --git a/tests/functions/test_pytorch_model.py b/tests/functions/test_pytorch_model.py
index f995fb8c..902fc6cd 100644
--- a/tests/functions/test_pytorch_model.py
+++ b/tests/functions/test_pytorch_model.py
@@ -1,13 +1,16 @@
 from collections import OrderedDict
 from contextlib import nullcontext
+from importlib import reload
 from typing import Union
 
 import numpy as np
 import pytest
 import torch
 from pytest_lazyfixture import lazy_fixture
-from quantus.helpers.model.pytorch_model import PyTorchModel
 from scipy.special import softmax
+from transformers import PreTrainedModel
+
+from quantus.helpers.model.pytorch_model import PyTorchModel
 
 
 @pytest.fixture
@@ -264,8 +267,12 @@ def test_add_mean_shift_to_first_layer(load_mnist_model):
         ),
         (
             lazy_fixture("load_hf_distilbert_sequence_classifier"),
-            {'input_ids': torch.tensor([[  101,  1996,  4248,  2829,  4419, 14523,  2058,  1996, 13971,  3899,
-                102]]), 'attention_mask': torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},
+            {
+                "input_ids": torch.tensor(
+                    [[101, 1996, 4248, 2829, 4419, 14523, 2058, 1996, 13971, 3899, 102]]
+                ),
+                "attention_mask": torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),
+            },
             False,
             {"labels": torch.tensor([1]), "output_hidden_states": True},
             nullcontext(np.array([[0.00424026, -0.03878461]])),
@@ -286,8 +293,40 @@ def test_add_mean_shift_to_first_layer(load_mnist_model):
         ),
     ],
 )
-def test_huggingface_classifier_predict(hf_model, data, softmax, model_kwargs, expected):
-    model = PyTorchModel(model=hf_model, softmax=softmax, model_predict_kwargs=model_kwargs)
+def test_huggingface_classifier_predict(
+    hf_model, data, softmax, model_kwargs, expected
+):
+    model = PyTorchModel(
+        model=hf_model, softmax=softmax, model_predict_kwargs=model_kwargs
+    )
     with expected:
         out = model.predict(x=data)
         assert np.allclose(out, expected.enter_result), "Test failed."
+
+
+@pytest.mark.pytorch_model
+@pytest.mark.parametrize(
+    "transformers_installed,base_class,expected",
+    [
+        (True, PreTrainedModel, nullcontext(np.array([[0.1, 0.9]], dtype=np.float32))),
+        (False, None, pytest.raises(ValueError)),
+    ],
+)
+def test_predict_transformers_installed(
+    mocker, transformers_installed, base_class, expected
+):
+    mocker.patch("importlib.util.find_spec", return_value=transformers_installed)
+    from quantus.helpers.model import pytorch_model
+
+    reload(pytorch_model)
+    # Mock the model's behavior
+    model_instance = PyTorchModel(model=mocker.MagicMock(spec=base_class))
+    model_instance.model.training = False
+    model_instance.model.return_value.logits = torch.tensor([[0.1, 0.9]])
+    model_instance.softmax = False
+
+    # Prepare input and call the predict method
+    x = {"input_ids": np.array([1, 2, 3]), "attention_mask": np.array([1, 1, 1])}
+    with expected:
+        predictions = model_instance.predict(x)
+        assert np.array_equal(predictions, expected.enter_result), "Test failed."
